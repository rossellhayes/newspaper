% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/newspaper.R
\name{newspaper_scrape}
\alias{newspaper_scrape}
\title{Scrape articles}
\usage{
newspaper_scrape(url, fields = c("title", "authors", "publish_date", "text"))
}
\arguments{
\item{url}{A character vector of URLs to scrape.}

\item{fields}{A character vector of fields to extract from each article.
A combination of \code{"title"}, \code{"authors"}, \code{"publish_date"}, and \code{"text"}.}
}
\value{
A \link[tibble:tibble]{tibble} with rows containing \code{fields} for
each \code{url}.
}
\description{
Scrape articles from online news sources using the
\href{https://newspaper.readthedocs.io/en/latest/}{newspaper Python package}.
}
\details{
Use \code{\link[=newspaper_install]{newspaper_install()}} to set up the Python environment needed to run
this function.
}
\examples{
newspaper_scrape(
  "https://www.businessinsider.com/what-is-web-scraping"
)

newspaper_scrape(
  "https://www.nature.com/articles/d41586-020-02558-0",
  fields = c("title", "text")
)

newspaper_scrape(
  "http://invalid.example"
)

newspaper_scrape(
  c(
    "https://www.businessinsider.com/what-is-web-scraping",
    "https://www.nature.com/articles/d41586-020-02558-0",
    "http://invalid.example"
  )
)
}
